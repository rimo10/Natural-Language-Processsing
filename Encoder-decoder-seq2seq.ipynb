{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "wSpjHRndTRjQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wDUXWKzQoI5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16500c93-4289-45c9-fd64-18335b731e41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-15 16:39:37--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 13.33.88.59, 13.33.88.36, 13.33.88.63, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|13.33.88.59|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "\rdata.zip              0%[                    ]       0  --.-KB/s               \rdata.zip            100%[===================>]   2.75M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-02-15 16:39:37 (74.0 MB/s) - ‘data.zip’ saved [2882130/2882130]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://download.pytorch.org/tutorial/data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "id": "UzshJwumJDY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6786c30c-be86-4120-e4e9-f06e67614e62"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/eng-fra.txt        \n",
            "   creating: data/names/\n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "xHVUyfyhTRl_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "metadata": {
        "id": "_mAWh-2ZUQM5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "q2dVVrGDUYSu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 15\n",
        "\n",
        "# eng_prefixes = (\n",
        "#     \"i am \", \"i m \",\n",
        "#     \"he is\", \"he s \",\n",
        "#     \"she is\", \"she s \",\n",
        "#     \"you are\", \"you re \",\n",
        "#     \"we are\", \"we re \",\n",
        "#     \"they are\", \"they re \"\n",
        "# )\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < max_length and \\\n",
        "        len(p[1].split(' ')) < max_length #and \\\n",
        "        # p[0].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "metadata": {
        "id": "8N1CAZoTUdiD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', False)\n",
        "# print(random.choice(pairs))"
      ],
      "metadata": {
        "id": "mp6mBSp-Upbp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9dbb3e6-5d6c-401a-dc7a-232ccbb02636"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 130143 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 12362\n",
            "fra 20391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_lang.word2count)"
      ],
      "metadata": {
        "id": "i9kjJK3_UwTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c50603a-53da-4c6b-f2e5-ece942ec12da"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12360"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.choice(pairs)"
      ],
      "metadata": {
        "id": "ONvGGk-CXkIY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9bfe34e-9a3b-4dd0-8d5e-8e2460a890a3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['don t expect anyone to help you .',\n",
              " 'ne t attends pas a ce que qui que ce soit t aide !']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_lang.word2index['come']"
      ],
      "metadata": {
        "id": "zlzVctpi_MnI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b108184-cc4f-4de7-f9d8-c5d738001243"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang,sentence):\n",
        "  return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang,sentence):\n",
        "  indexes=indexesFromSentence(lang,sentence)\n",
        "  indexes.append(EOS_token)\n",
        "  return torch.tensor(indexes,dtype=torch.long,device=device).view(-1,1)\n",
        "\n",
        "def tensorsFromPair(input_lang,output_lang,pair):\n",
        "  input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "  target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "  return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "YUN3I5Cp-t1U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent=pairs[90000][0]\n",
        "indexesFromSentence(input_lang,sent)"
      ],
      "metadata": {
        "id": "ll--yAaYPjqX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73a573ad-eb79-493a-d571-da1c3ca04255"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[164, 108, 951, 2410, 200, 235, 53, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,embedding_size=256,num_layers=1):\n",
        "    super(EncoderRNN,self).__init__()\n",
        "    self.input_size=input_size\n",
        "    self.hidden_size=hidden_size\n",
        "    self.embedding_size=embedding_size\n",
        "    self.num_layers=num_layers\n",
        "    self.embedding=nn.Embedding(input_size,self.embedding_size)\n",
        "    self.gru=nn.GRU(self.embedding_size,self.hidden_size,num_layers=self.num_layers)\n",
        "\n",
        "  def forward(self,input,hidden):\n",
        "    embedded=self.embedding(input).view(1,1,-1)\n",
        "    output=embedded\n",
        "    output,hidden=self.gru(output,hidden)\n",
        "    return output,hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(self.num_layers,1,self.hidden_size,device=device)"
      ],
      "metadata": {
        "id": "Iv9gL7GGX7Qn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "  def __init__(self,output_size,hidden_size,embedding_size=256,num_layers=1):\n",
        "    super().__init__()\n",
        "    self.output_size=output_size\n",
        "    self.hidden_size=hidden_size\n",
        "    self.embedding_size=embedding_size\n",
        "    self.num_layers=num_layers\n",
        "    self.embedding=nn.Embedding(output_size,embedding_size)\n",
        "    self.gru=nn.GRU(self.embedding_size,hidden_size,num_layers=num_layers)\n",
        "    self.out=nn.Linear(hidden_size,output_size)\n",
        "    self.softmax=nn.LogSoftmax(dim=1)\n",
        "  \n",
        "  def forward(self,input,hidden):\n",
        "    output=self.embedding(input).view(1,1,-1)\n",
        "    embedd=F.relu(output)\n",
        "    output,hidden=self.gru(embedd,hidden)\n",
        "    prediction=self.softmax(self.out(output[0]))\n",
        "    return prediction,hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(self.num_layers,1,self.hidden_size,device=device)"
      ],
      "metadata": {
        "id": "DP9vqm-2nF78"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class Seq2Seq(nn.Module):\n",
        "#   def __init__(self,encoder,decoder,device,MAX_LENGTH=MAX_LENGTH):\n",
        "#     super().__init__()\n",
        "#     self.encoder=encoder\n",
        "#     self.decoder=decoder\n",
        "#     self.device=device\n",
        "  \n",
        "#   def forward(self,source,target,teacher_forcing_ratio=0.5):\n",
        "#     input_length=source.size(0)\n",
        "#     batch_size=target.shape[1]\n",
        "#     target_length=target.shape[0]\n",
        "#     vocab_size=self.decoder.output_size\n",
        "\n",
        "#     #Initialize a variable to hold the predicted outputs\n",
        "#     outputs=torch.zeros(target_length,batch_size,vocab_size).to(device)\n",
        "    \n",
        "#     #encode every word in the sentence\n",
        "#     for i in range(input_length):\n",
        "#       encoder_output,encoder_hidden=self.encoder(source[i])\n",
        "    \n",
        "#     #Use encoder's hidden layer as decoder hidden\n",
        "#     decoder_hidden=encoder_hidden.to(device)\n",
        "\n",
        "#     #add a token before the first predicted word\n",
        "#     decoder_input=torch.tensor([SOS_token],device=device)\n",
        "\n",
        "#     #topk is used to get the top K value over a list\n",
        "#     #predict the output word from the current target word. If we enable the teaching force,  then the #next decoder input is the next word, else, use the decoder output highest value. \n",
        "#     for t in range(target_length):\n",
        "#       decoder_output,decoder_hidden=self.decoder(decoder_input,decoder_hidden)\n",
        "#       outputs[t]=decoder_output\n",
        "#       teacher_force=random.random() < teacher_forcing_ratio\n",
        "#       topv,topi=decoder_output.topk(1)\n",
        "#       input=(target[t] if teacher_force else topi)\n",
        "#       if(teacher_force==False and input.item()==EOS_token):\n",
        "#         break\n",
        "    \n",
        "#     return outputs\n"
      ],
      "metadata": {
        "id": "1GOAIdLot-ud"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# teacher_forcing_ratio=0.5\n",
        "# def clacModel(model,input_tensor,target_tensor,optimizer,criterion):\n",
        "#   optimizer.zero_grad()\n",
        "#   input_length=input_tensor.size(0)\n",
        "#   loss=0\n",
        "#   epoch_loss=0\n",
        "#   output=model(input_tensor,target_tensor)\n",
        "#   num_iter=output.size(0)\n",
        "#   #Calculate loss from predicted sentence with expected result\n",
        "#   for i in range(num_iter):\n",
        "#     loss+=criterion(output[i],target_tensor[i])\n",
        "#   loss.backward()\n",
        "#   optimizer.step()\n",
        "#   epoch_loss=loss.item()/num_iter\n",
        "#   return epoch_loss"
      ],
      "metadata": {
        "id": "A_v9nUfSRMtd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train(model,source,target,pairs,num_iteration=200000):\n",
        "#   model.train()\n",
        "#   optimizer=optim.SGD(model.parameters(),lr=0.01)\n",
        "#   criterion=nn.NLLLoss()\n",
        "#   total_loss_iterations=0\n",
        "\n",
        "#   training_pairs=[tensorsFromPair(source,target,random.choice(pairs)) for i in range(num_iteration)]\n",
        "#   for iter in range(1,num_iteration+1):\n",
        "#     training_pair=[iter-1]\n",
        "#     input_tensor=training_pair[0]\n",
        "\n",
        "#     target_tensor=training_pair[1]\n",
        "#     loss=clacModel(model,input_tensor,target_tensor,optimizer,criterion)\n",
        "    \n",
        "#     total_loss_iterations+=loss\n",
        "\n",
        "#     if iter%5000==0:\n",
        "#       average_loss=total_loss_iterations/5000\n",
        "#       total_loss_iterations=0\n",
        "#       print('%d %.4f'%(iter,average_loss))\n",
        "    \n",
        "#   torch.save(model.state_dict(),'mytraining.pt')"
      ],
      "metadata": {
        "id": "Y2WqKNf4-aWf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio=0.5"
      ],
      "metadata": {
        "id": "CPiF9BCTAsT1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(input_tensor,target_tensor,encoder,decoder,encoder_optimizer,decoder_optimizer,criterion,max_length):\n",
        "  encoder_optimizer.zero_grad()\n",
        "  decoder_optimizer.zero_grad()\n",
        "  input_length=input_tensor.size(0)\n",
        "  target_length=target_tensor.size(0)\n",
        "  encoder_hidden=encoder.init_hidden()\n",
        "  encoder_outputs=torch.zeros(max_length,encoder.hidden_size,device=device)\n",
        "  loss=0\n",
        "  for ei in range(input_length):\n",
        "    encoder_output,encoder_hidden=encoder(\n",
        "        input_tensor[ei],encoder_hidden\n",
        "    )\n",
        "    # print(encoder_output.shape)\n",
        "    # print(encoder_hidden.shape)\n",
        "    encoder_outputs[ei]=encoder_output[0,0]\n",
        "  decoder_input=torch.tensor([[SOS_token]],device=device)\n",
        "  decoder_hidden=encoder_hidden\n",
        "\n",
        "  teacher_forcing=True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "  if teacher_forcing:\n",
        "      # Teacher forcing: Feed the target as the next input\n",
        "      for di in range(target_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "        loss += criterion(decoder_output, target_tensor[di])\n",
        "        decoder_input = target_tensor[di]  # Teacher forcing\n",
        "  else:\n",
        "    # Without teacher forcing: use its own predictions as the next input\n",
        "    for di in range(target_length):\n",
        "      decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "      topv, topi = decoder_output.topk(1)\n",
        "      decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "      if decoder_input.item() == EOS_token:\n",
        "        break\n",
        "  loss.backward()\n",
        "  encoder_optimizer.step()\n",
        "  decoder_optimizer.step()\n",
        "  return loss.item()/(target_length)"
      ],
      "metadata": {
        "id": "de-oQyfw2mGt"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_iter(pairs,encoder,decoder,num_iters,max_length,lr=0.005):\n",
        "  encoder_optimizer=torch.optim.SGD(encoder.parameters(),lr)\n",
        "  decoder_optimizer=torch.optim.SGD(decoder.parameters(),lr)\n",
        "  training_pairs=[tensorsFromPair(input_lang,output_lang,random.choice(pairs)) for i in range(num_iters)]\n",
        "  criterion=nn.NLLLoss()\n",
        "  total_loss=0\n",
        "  for iter in range(1,(num_iters+1)):\n",
        "    training_pair=training_pairs[iter-1]\n",
        "    input_tensor=training_pair[0]\n",
        "    target_tensor=training_pair[1]\n",
        "    loss=train(input_tensor,target_tensor,encoder,decoder,encoder_optimizer,decoder_optimizer,criterion,max_length)\n",
        "    total_loss+=loss\n",
        "\n",
        "    if iter%5000==0:\n",
        "      train_loss=total_loss/5000\n",
        "      val_loss=evaluate(tensorsFromPair(input_lang,output_lang,random.choice(pairs)),encoder,decoder,criterion,max_length)\n",
        "      print('Iter:{} , Train_Loss:{:.4f}, Val_Loss:{:.4}'.format(iter,train_loss,val_loss))"
      ],
      "metadata": {
        "id": "c9f6g_-i2mJW"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(pair,encoder,decoder,criterion,max_length):\n",
        "  encoder_hidden=encoder.init_hidden()\n",
        "  input_tensor=pair[0]\n",
        "  target_tensor=pair[1]\n",
        "  input_length=input_tensor.size()[0]\n",
        "  target_length=target_tensor.size()[0]\n",
        "  encoder_outputs=torch.zeros(max_length,encoder.hidden_size,device=device)\n",
        "  loss=0\n",
        "  for ei in range(input_length):\n",
        "    encoder_output,encoder_hidden=encoder(\n",
        "        input_tensor[ei],encoder_hidden\n",
        "    )\n",
        "    encoder_outputs[ei]+=encoder_output[0,0]\n",
        "  decoder_input=torch.tensor([[SOS_token]],device=device)\n",
        "  decoder_hidden=encoder_hidden\n",
        "\n",
        "  for di in range(target_length):\n",
        "    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "    topv, topi = decoder_output.topk(1)\n",
        "    decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "    loss += criterion(decoder_output, target_tensor[di])\n",
        "    if decoder_input.item() == EOS_token:\n",
        "      break\n",
        "  return loss.item()/target_length"
      ],
      "metadata": {
        "id": "ceV1AuW02mM4"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lang1='eng'\n",
        "lang2='fra'\n",
        "input_size=input_lang.n_words\n",
        "output_size=output_lang.n_words\n",
        "embed_size=256\n",
        "hidden_size=512\n",
        "num_layers=4\n",
        "num_iters=100000\n",
        "\n",
        "encoder=EncoderRNN(input_size,hidden_size,embed_size,num_layers).to(device)\n",
        "decoder=DecoderRNN(output_size,hidden_size,embed_size,num_layers).to(device)\n",
        "# model=Seq2Seq(encoder,decoder,device).to(device)"
      ],
      "metadata": {
        "id": "synolrxqQud0"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter(pairs,encoder,decoder,num_iters,max_length,lr=0.005)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiZpNNNGB6Y5",
        "outputId": "d3cd63c1-b618-4e59-862b-3aba39a5e95c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter:5000 , Train_Loss:5.1452, Val_Loss:2.915\n",
            "Iter:10000 , Train_Loss:9.6939, Val_Loss:5.349\n",
            "Iter:15000 , Train_Loss:14.0969, Val_Loss:3.588\n",
            "Iter:20000 , Train_Loss:18.3665, Val_Loss:5.897\n",
            "Iter:25000 , Train_Loss:22.5022, Val_Loss:4.118\n",
            "Iter:30000 , Train_Loss:26.5093, Val_Loss:5.968\n",
            "Iter:35000 , Train_Loss:30.3810, Val_Loss:6.373\n",
            "Iter:40000 , Train_Loss:34.1577, Val_Loss:4.265\n",
            "Iter:45000 , Train_Loss:37.8428, Val_Loss:5.412\n",
            "Iter:50000 , Train_Loss:41.4590, Val_Loss:3.759\n",
            "Iter:55000 , Train_Loss:45.0142, Val_Loss:2.89\n",
            "Iter:60000 , Train_Loss:48.5010, Val_Loss:4.089\n",
            "Iter:65000 , Train_Loss:51.9370, Val_Loss:4.548\n",
            "Iter:70000 , Train_Loss:55.2462, Val_Loss:2.726\n",
            "Iter:75000 , Train_Loss:58.5295, Val_Loss:2.321\n",
            "Iter:80000 , Train_Loss:61.7562, Val_Loss:2.223\n",
            "Iter:85000 , Train_Loss:64.9359, Val_Loss:1.606\n",
            "Iter:90000 , Train_Loss:68.0708, Val_Loss:1.747\n",
            "Iter:95000 , Train_Loss:71.1437, Val_Loss:2.165\n",
            "Iter:100000 , Train_Loss:74.1686, Val_Loss:3.477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(encoder,decoder,sentence,max_length=max_length):\n",
        "  with torch.no_grad():\n",
        "    input_tensor=tensorFromSentence(input_lang,sentence)\n",
        "    input_length=input_tensor.size()[0]\n",
        "    encoder_hidden=encoder.init_hidden()\n",
        "    encoder_outputs=torch.zeros(max_length,encoder.hidden_size,device=device)\n",
        "    # Encoder\n",
        "    for ei in range(input_length):\n",
        "      encoder_output,encoder_hidden=encoder(input_tensor[ei],encoder_hidden)\n",
        "      encoder_outputs[ei]+=encoder_output[0,0]\n",
        "    # Decoder\n",
        "    decoder_input=torch.tensor([[SOS_token]],device=device)\n",
        "    decoder_hidden=encoder_hidden\n",
        "    decoded_words=[]\n",
        "    for di in range(max_length):\n",
        "      decoder_output,decoder_hidden=decoder(decoder_input,decoder_hidden)\n",
        "      topv,topi=decoder_output.data.topk(1)\n",
        "      if topi.item()==EOS_token:\n",
        "        decoded_words.append('<EOS>')\n",
        "      else:\n",
        "        decoded_words.append(output_lang.index2word[topi.item()])\n",
        "      decoder_input=topi.squeeze().detach()\n",
        "    \n",
        "    return decoded_words"
      ],
      "metadata": {
        "id": "AAX407pnDgIb"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction(encoder,decoder,sentence,max_length):\n",
        "  output_arr=predict(encoder,decoder,sentence,max_length)\n",
        "  output_words=' '.join(output_arr)\n",
        "  return output_words"
      ],
      "metadata": {
        "id": "Ik3f6BXYHJZV"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence='he is speaking fluent in french'\n",
        "output=get_prediction(encoder,decoder,sentence,max_length)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIMHLFinHxOp",
        "outputId": "7bffe69e-109b-4cb7-a0b4-895d737e9570"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "il est en francais au francais francais . <EOS> <EOS> <EOS> . <EOS> <EOS> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence='the world is a beautiful place to live in'\n",
        "output=get_prediction(encoder,decoder,sentence,max_length)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBfoPJ3SWCWn",
        "outputId": "15ccdefb-b060-4c55-f43a-63d7f6b71cdb"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "le monde est une qui est qui dans dans la <EOS> . <EOS> . <EOS>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence='we are here to protect you'\n",
        "output=get_prediction(encoder,decoder,sentence,max_length)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEV7qr7jWbAC",
        "outputId": "79601a3f-5888-44d0-d55c-3a37c799226b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nous sommes ici pour toi . <EOS> . <EOS> . <EOS> . <EOS> . <EOS>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(encoder.state_dict(),'encoder.pt')\n",
        "torch.save(decoder.state_dict(),'decoder.pt')"
      ],
      "metadata": {
        "id": "btDCu0HNIPQl"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f9v4CvJjVOTI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}