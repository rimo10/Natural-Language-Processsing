{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "wSpjHRndTRjQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wDUXWKzQoI5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4ae5a48-eaca-4503-a47e-2a4b748ad19c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-17 20:47:52--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 54.192.150.27, 54.192.150.31, 54.192.150.110, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|54.192.150.27|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   2.75M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-02-17 20:47:53 (76.1 MB/s) - ‘data.zip’ saved [2882130/2882130]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://download.pytorch.org/tutorial/data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "id": "UzshJwumJDY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7024704-0fc3-41bb-8dc7-d19270a070c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/eng-fra.txt        \n",
            "   creating: data/names/\n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "xHVUyfyhTRl_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "metadata": {
        "id": "_mAWh-2ZUQM5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "q2dVVrGDUYSu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 15\n",
        "\n",
        "# eng_prefixes = (\n",
        "#     \"i am \", \"i m \",\n",
        "#     \"he is\", \"he s \",\n",
        "#     \"she is\", \"she s \",\n",
        "#     \"you are\", \"you re \",\n",
        "#     \"we are\", \"we re \",\n",
        "#     \"they are\", \"they re \"\n",
        "# )\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < max_length and \\\n",
        "        len(p[1].split(' ')) < max_length #and \\\n",
        "        # p[0].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "metadata": {
        "id": "8N1CAZoTUdiD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', False)\n",
        "# print(random.choice(pairs))"
      ],
      "metadata": {
        "id": "mp6mBSp-Upbp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46361651-3fa8-426b-902a-2610bdd40206"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 130143 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 12362\n",
            "fra 20391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_lang.word2count)"
      ],
      "metadata": {
        "id": "i9kjJK3_UwTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87655a3c-cae8-4d24-caeb-99f107b987b9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12360"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.choice(pairs)"
      ],
      "metadata": {
        "id": "ONvGGk-CXkIY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1962c1df-92e5-4a8f-bb43-ba5e8439673e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['did you come here alone ?', 'etes vous venu seul ici ?']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_lang.word2index['come']"
      ],
      "metadata": {
        "id": "zlzVctpi_MnI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f20491d-4791-44e4-b1e1-e521dcbb9a7c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang,sentence):\n",
        "  return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang,sentence):\n",
        "  indexes=indexesFromSentence(lang,sentence)\n",
        "  indexes.append(EOS_token)\n",
        "  return torch.tensor(indexes,dtype=torch.long,device=device).view(-1,1)\n",
        "\n",
        "def tensorsFromPair(input_lang,output_lang,pair):\n",
        "  input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "  target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "  return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "YUN3I5Cp-t1U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent=pairs[90000][0]\n",
        "indexesFromSentence(input_lang,sent)"
      ],
      "metadata": {
        "id": "ll--yAaYPjqX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd6afc12-53a7-47ce-b732-624df2a900bf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[164, 108, 951, 2410, 200, 235, 53, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,embedding_size=256,num_layers=1):\n",
        "    super(EncoderRNN,self).__init__()\n",
        "    self.input_size=input_size\n",
        "    self.hidden_size=hidden_size\n",
        "    self.embedding_size=embedding_size\n",
        "    self.num_layers=num_layers\n",
        "    self.embedding=nn.Embedding(input_size,self.embedding_size)\n",
        "    self.gru=nn.GRU(self.embedding_size,self.hidden_size,num_layers=self.num_layers)\n",
        "\n",
        "  def forward(self,input,hidden):\n",
        "    embedded=self.embedding(input).view(1,1,-1)\n",
        "    output=embedded\n",
        "    output,hidden=self.gru(output,hidden)\n",
        "    return output,hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(self.num_layers,1,self.hidden_size,device=device)"
      ],
      "metadata": {
        "id": "Iv9gL7GGX7Qn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "  def __init__(self,output_size,hidden_size,embedding_size=256,num_layers=1):\n",
        "    super().__init__()\n",
        "    self.output_size=output_size\n",
        "    self.hidden_size=hidden_size\n",
        "    self.embedding_size=embedding_size\n",
        "    self.num_layers=num_layers\n",
        "    self.embedding=nn.Embedding(output_size,embedding_size)\n",
        "    self.gru=nn.GRU(self.embedding_size,hidden_size,num_layers=num_layers)\n",
        "    self.out=nn.Linear(hidden_size,output_size)\n",
        "    self.softmax=nn.LogSoftmax(dim=1)\n",
        "  \n",
        "  def forward(self,input,hidden):\n",
        "    output=self.embedding(input).view(1,1,-1)\n",
        "    embedd=F.relu(output)\n",
        "    output,hidden=self.gru(embedd,hidden)\n",
        "    prediction=self.softmax(self.out(output[0]))\n",
        "    return prediction,hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(self.num_layers,1,self.hidden_size,device=device)"
      ],
      "metadata": {
        "id": "DP9vqm-2nF78"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class Seq2Seq(nn.Module):\n",
        "#   def __init__(self,encoder,decoder,device,MAX_LENGTH=MAX_LENGTH):\n",
        "#     super().__init__()\n",
        "#     self.encoder=encoder\n",
        "#     self.decoder=decoder\n",
        "#     self.device=device\n",
        "  \n",
        "#   def forward(self,source,target,teacher_forcing_ratio=0.5):\n",
        "#     input_length=source.size(0)\n",
        "#     batch_size=target.shape[1]\n",
        "#     target_length=target.shape[0]\n",
        "#     vocab_size=self.decoder.output_size\n",
        "\n",
        "#     #Initialize a variable to hold the predicted outputs\n",
        "#     outputs=torch.zeros(target_length,batch_size,vocab_size).to(device)\n",
        "    \n",
        "#     #encode every word in the sentence\n",
        "#     for i in range(input_length):\n",
        "#       encoder_output,encoder_hidden=self.encoder(source[i])\n",
        "    \n",
        "#     #Use encoder's hidden layer as decoder hidden\n",
        "#     decoder_hidden=encoder_hidden.to(device)\n",
        "\n",
        "#     #add a token before the first predicted word\n",
        "#     decoder_input=torch.tensor([SOS_token],device=device)\n",
        "\n",
        "#     #topk is used to get the top K value over a list\n",
        "#     #predict the output word from the current target word. If we enable the teaching force,  then the #next decoder input is the next word, else, use the decoder output highest value. \n",
        "#     for t in range(target_length):\n",
        "#       decoder_output,decoder_hidden=self.decoder(decoder_input,decoder_hidden)\n",
        "#       outputs[t]=decoder_output\n",
        "#       teacher_force=random.random() < teacher_forcing_ratio\n",
        "#       topv,topi=decoder_output.topk(1)\n",
        "#       input=(target[t] if teacher_force else topi)\n",
        "#       if(teacher_force==False and input.item()==EOS_token):\n",
        "#         break\n",
        "    \n",
        "#     return outputs\n"
      ],
      "metadata": {
        "id": "1GOAIdLot-ud"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# teacher_forcing_ratio=0.5\n",
        "# def clacModel(model,input_tensor,target_tensor,optimizer,criterion):\n",
        "#   optimizer.zero_grad()\n",
        "#   input_length=input_tensor.size(0)\n",
        "#   loss=0\n",
        "#   epoch_loss=0\n",
        "#   output=model(input_tensor,target_tensor)\n",
        "#   num_iter=output.size(0)\n",
        "#   #Calculate loss from predicted sentence with expected result\n",
        "#   for i in range(num_iter):\n",
        "#     loss+=criterion(output[i],target_tensor[i])\n",
        "#   loss.backward()\n",
        "#   optimizer.step()\n",
        "#   epoch_loss=loss.item()/num_iter\n",
        "#   return epoch_loss"
      ],
      "metadata": {
        "id": "A_v9nUfSRMtd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train(model,source,target,pairs,num_iteration=200000):\n",
        "#   model.train()\n",
        "#   optimizer=optim.SGD(model.parameters(),lr=0.01)\n",
        "#   criterion=nn.NLLLoss()\n",
        "#   total_loss_iterations=0\n",
        "\n",
        "#   training_pairs=[tensorsFromPair(source,target,random.choice(pairs)) for i in range(num_iteration)]\n",
        "#   for iter in range(1,num_iteration+1):\n",
        "#     training_pair=[iter-1]\n",
        "#     input_tensor=training_pair[0]\n",
        "\n",
        "#     target_tensor=training_pair[1]\n",
        "#     loss=clacModel(model,input_tensor,target_tensor,optimizer,criterion)\n",
        "    \n",
        "#     total_loss_iterations+=loss\n",
        "\n",
        "#     if iter%5000==0:\n",
        "#       average_loss=total_loss_iterations/5000\n",
        "#       total_loss_iterations=0\n",
        "#       print('%d %.4f'%(iter,average_loss))\n",
        "    \n",
        "#   torch.save(model.state_dict(),'mytraining.pt')"
      ],
      "metadata": {
        "id": "Y2WqKNf4-aWf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio=0.5"
      ],
      "metadata": {
        "id": "CPiF9BCTAsT1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(input_tensor,target_tensor,encoder,decoder,encoder_optimizer,decoder_optimizer,criterion,max_length):\n",
        "  encoder_optimizer.zero_grad()\n",
        "  decoder_optimizer.zero_grad()\n",
        "  input_length=input_tensor.size(0)\n",
        "  target_length=target_tensor.size(0)\n",
        "  encoder_hidden=encoder.init_hidden()\n",
        "  encoder_outputs=torch.zeros(max_length,encoder.hidden_size,device=device)\n",
        "  loss=0\n",
        "  for ei in range(input_length):\n",
        "    encoder_output,encoder_hidden=encoder(\n",
        "        input_tensor[ei],encoder_hidden\n",
        "    )\n",
        "    # print(encoder_output.shape)\n",
        "    # print(encoder_hidden.shape)\n",
        "    encoder_outputs[ei]=encoder_output[0,0]\n",
        "  decoder_input=torch.tensor([[SOS_token]],device=device)\n",
        "  decoder_hidden=encoder_hidden\n",
        "\n",
        "  teacher_forcing=True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "  if teacher_forcing:\n",
        "      # Teacher forcing: Feed the target as the next input\n",
        "      for di in range(target_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "        loss += criterion(decoder_output, target_tensor[di])\n",
        "        decoder_input = target_tensor[di]  # Teacher forcing\n",
        "  else:\n",
        "    # Without teacher forcing: use its own predictions as the next input\n",
        "    for di in range(target_length):\n",
        "      decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "      topv, topi = decoder_output.topk(1)\n",
        "      decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "      if decoder_input.item() == EOS_token:\n",
        "        break\n",
        "  loss.backward()\n",
        "  encoder_optimizer.step()\n",
        "  decoder_optimizer.step()\n",
        "  return loss.item()/(target_length)"
      ],
      "metadata": {
        "id": "de-oQyfw2mGt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_iter(pairs,encoder,decoder,num_iters,max_length,lr=0.005):\n",
        "  encoder_optimizer=torch.optim.SGD(encoder.parameters(),lr)\n",
        "  decoder_optimizer=torch.optim.SGD(decoder.parameters(),lr)\n",
        "  training_pairs=[tensorsFromPair(input_lang,output_lang,random.choice(pairs)) for i in range(num_iters)]\n",
        "  criterion=nn.NLLLoss()\n",
        "  total_loss=0\n",
        "  for iter in range(1,(num_iters+1)):\n",
        "    training_pair=training_pairs[iter-1]\n",
        "    input_tensor=training_pair[0]\n",
        "    target_tensor=training_pair[1]\n",
        "    loss=train(input_tensor,target_tensor,encoder,decoder,encoder_optimizer,decoder_optimizer,criterion,max_length)\n",
        "    total_loss+=loss\n",
        "\n",
        "    if iter%5000==0:\n",
        "      train_loss=total_loss/5000\n",
        "      total_loss=0\n",
        "      val_loss=evaluate(tensorsFromPair(input_lang,output_lang,random.choice(pairs)),encoder,decoder,criterion,max_length)\n",
        "      print('Iter:{} , Train_Loss:{:.4f}, Val_Loss:{:.4}'.format(iter,train_loss,val_loss))"
      ],
      "metadata": {
        "id": "c9f6g_-i2mJW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(pair,encoder,decoder,criterion,max_length):\n",
        "  encoder_hidden=encoder.init_hidden()\n",
        "  input_tensor=pair[0]\n",
        "  target_tensor=pair[1]\n",
        "  input_length=input_tensor.size()[0]\n",
        "  target_length=target_tensor.size()[0]\n",
        "  encoder_outputs=torch.zeros(max_length,encoder.hidden_size,device=device)\n",
        "  loss=0\n",
        "  for ei in range(input_length):\n",
        "    encoder_output,encoder_hidden=encoder(\n",
        "        input_tensor[ei],encoder_hidden\n",
        "    )\n",
        "    encoder_outputs[ei]+=encoder_output[0,0]\n",
        "  decoder_input=torch.tensor([[SOS_token]],device=device)\n",
        "  decoder_hidden=encoder_hidden\n",
        "\n",
        "  for di in range(target_length):\n",
        "    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "    topv, topi = decoder_output.topk(1)\n",
        "    decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "    loss += criterion(decoder_output, target_tensor[di])\n",
        "    if decoder_input.item() == EOS_token:\n",
        "      break\n",
        "  return loss.item()/target_length"
      ],
      "metadata": {
        "id": "ceV1AuW02mM4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lang1='eng'\n",
        "lang2='fra'\n",
        "input_size=input_lang.n_words\n",
        "output_size=output_lang.n_words\n",
        "embed_size=256\n",
        "hidden_size=512\n",
        "num_layers=4\n",
        "num_iters=100000\n",
        "\n",
        "encoder=EncoderRNN(input_size,hidden_size,embed_size,num_layers).to(device)\n",
        "decoder=DecoderRNN(output_size,hidden_size,embed_size,num_layers).to(device)\n",
        "# model=Seq2Seq(encoder,decoder,device).to(device)"
      ],
      "metadata": {
        "id": "synolrxqQud0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter(pairs,encoder,decoder,num_iters,max_length,lr=0.005)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiZpNNNGB6Y5",
        "outputId": "33322ec5-5806-4e74-bc8b-1e7a122f3f5a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter:5000 , Train_Loss:5.1404, Val_Loss:3.208\n",
            "Iter:10000 , Train_Loss:4.6025, Val_Loss:4.658\n",
            "Iter:15000 , Train_Loss:4.4177, Val_Loss:5.139\n",
            "Iter:20000 , Train_Loss:4.2552, Val_Loss:2.443\n",
            "Iter:25000 , Train_Loss:4.0847, Val_Loss:3.816\n",
            "Iter:30000 , Train_Loss:3.9758, Val_Loss:4.534\n",
            "Iter:35000 , Train_Loss:3.8521, Val_Loss:3.3\n",
            "Iter:40000 , Train_Loss:3.7556, Val_Loss:2.942\n",
            "Iter:45000 , Train_Loss:3.6914, Val_Loss:3.149\n",
            "Iter:50000 , Train_Loss:3.5595, Val_Loss:4.86\n",
            "Iter:55000 , Train_Loss:3.5127, Val_Loss:4.825\n",
            "Iter:60000 , Train_Loss:3.4227, Val_Loss:2.294\n",
            "Iter:65000 , Train_Loss:3.3857, Val_Loss:4.516\n",
            "Iter:70000 , Train_Loss:3.3626, Val_Loss:4.115\n",
            "Iter:75000 , Train_Loss:3.2820, Val_Loss:3.901\n",
            "Iter:80000 , Train_Loss:3.1897, Val_Loss:3.469\n",
            "Iter:85000 , Train_Loss:3.1195, Val_Loss:4.743\n",
            "Iter:90000 , Train_Loss:3.1509, Val_Loss:2.236\n",
            "Iter:95000 , Train_Loss:3.0752, Val_Loss:4.493\n",
            "Iter:100000 , Train_Loss:3.0410, Val_Loss:3.015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(encoder,decoder,sentence,max_length=max_length):\n",
        "  with torch.no_grad():\n",
        "    input_tensor=tensorFromSentence(input_lang,sentence)\n",
        "    input_length=input_tensor.size(0)\n",
        "    encoder_hidden=encoder.init_hidden()\n",
        "    encoder_outputs=torch.zeros(max_length,encoder.hidden_size,device=device)\n",
        "    # Encoder\n",
        "    for ei in range(input_length):\n",
        "      encoder_output,encoder_hidden=encoder(input_tensor[ei],encoder_hidden)\n",
        "      encoder_outputs[ei]+=encoder_output[0,0]\n",
        "    # Decoder\n",
        "    decoder_input=torch.tensor([[SOS_token]],device=device)\n",
        "    decoder_hidden=encoder_hidden\n",
        "    decoded_words=[]\n",
        "    for di in range(max_length):\n",
        "      decoder_output,decoder_hidden=decoder(decoder_input,decoder_hidden)\n",
        "      topv,topi=decoder_output.data.topk(1)\n",
        "      if topi.item()==EOS_token:\n",
        "        decoded_words.append('<EOS>')\n",
        "        break;\n",
        "      else:\n",
        "        decoded_words.append(output_lang.index2word[topi.item()])\n",
        "      decoder_input=topi.squeeze().detach()\n",
        "    \n",
        "    return decoded_words"
      ],
      "metadata": {
        "id": "AAX407pnDgIb"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction(encoder,decoder,sentence,max_length):\n",
        "  output_arr=predict(encoder,decoder,sentence,max_length)\n",
        "  output_words=' '.join(output_arr)\n",
        "  return output_words"
      ],
      "metadata": {
        "id": "Ik3f6BXYHJZV"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence='he is speaking fluent in french'\n",
        "output=get_prediction(encoder,decoder,sentence,max_length)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIMHLFinHxOp",
        "outputId": "1242489e-29df-4424-9e3c-86fe8472ac5b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "il est arrive a parler francais . <EOS>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence='the world is a beautiful place to live in'\n",
        "output=get_prediction(encoder,decoder,sentence,max_length)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBfoPJ3SWCWn",
        "outputId": "3ab9663c-86d3-44c0-bc9a-9d18c3c9788d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "le route est un un d un <EOS>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence='we are here to protect you'\n",
        "output=get_prediction(encoder,decoder,sentence,max_length)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEV7qr7jWbAC",
        "outputId": "9c8f48c5-0493-479c-9e53-78107cdc35bc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nous sommes alles ici ? <EOS>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence='i am not giving you my car'\n",
        "output=get_prediction(encoder,decoder,sentence,max_length)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N0uxbsHX5PL",
        "outputId": "d9a77e1e-b4e8-4548-8579-648b536dadf1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "je ne vous pas ma voiture ? <EOS>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(encoder.state_dict(),'encoder.pt')\n",
        "torch.save(decoder.state_dict(),'decoder.pt')"
      ],
      "metadata": {
        "id": "btDCu0HNIPQl"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f9v4CvJjVOTI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}